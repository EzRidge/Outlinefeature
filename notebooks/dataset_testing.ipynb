{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Testing Notebook\n",
    "\n",
    "This notebook tests each dataset individually:\n",
    "1. RID Dataset (Segmentation)\n",
    "2. Roofline Dataset (Line Detection)\n",
    "3. AIRS Dataset (Building Outlines)\n",
    "\n",
    "Each dataset has its own implementation in src/datasets/, sharing common functionality through a base class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Add project root to path\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get absolute path to project root\n",
    "notebook_dir = Path(os.getcwd())\n",
    "project_root = notebook_dir.parent\n",
    "print(f\"Project root: {project_root}\")\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import dependencies\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Import our modules\n",
    "from src.datasets import create_dataloaders\n",
    "from src.models import create_model\n",
    "\n",
    "# Set up logging and plotting\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Training settings\n",
    "config = {\n",
    "    'batch_size': 2,\n",
    "    'num_workers': 2,\n",
    "    'max_samples': 10,\n",
    "    'image_size': 512,\n",
    "    'num_classes': 12\n",
    "}\n",
    "\n",
    "# Dataset paths\n",
    "data_paths = {\n",
    "    'rid': project_root / 'Reference Materials' / 'data' / 'RID' / 'm1655470' / 'RID_dataset',\n",
    "    'roofline': project_root / 'Reference Materials' / 'data' / 'Roofline-Extraction',\n",
    "    'airs': project_root / 'Reference Materials' / 'data' / 'AIRS'\n",
    "}\n",
    "\n",
    "# Verify paths exist\n",
    "print(\"\\nVerifying dataset paths:\")\n",
    "for name, path in data_paths.items():\n",
    "    print(f\"\\n{name} dataset:\")\n",
    "    print(f\"Path: {path}\")\n",
    "    print(f\"Exists: {path.exists()}\")\n",
    "    if path.exists():\n",
    "        print(\"Contents:\")\n",
    "        for item in path.iterdir():\n",
    "            if item.is_dir():\n",
    "                print(f\"  - {item.name}/\")\n",
    "            else:\n",
    "                print(f\"  - {item.name}\")\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'\\nUsing device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def show_batch(images, targets, dataset_type):\n",
    "    \"\"\"Display a batch of images and their targets.\"\"\"\n",
    "    batch_size = images.shape[0]\n",
    "    fig, axes = plt.subplots(batch_size, 4, figsize=(20, 5*batch_size))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Original image\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        axes[i,0].imshow(img)\n",
    "        axes[i,0].set_title('Original Image')\n",
    "        \n",
    "        # Segmentation mask\n",
    "        mask = targets['segments'][i].numpy()\n",
    "        axes[i,1].imshow(mask, cmap='tab20')\n",
    "        axes[i,1].set_title('Segmentation Mask')\n",
    "        \n",
    "        # Line detection\n",
    "        lines = targets['lines'][i].numpy()\n",
    "        line_vis = np.zeros((*lines.shape[1:], 3))\n",
    "        line_vis[...,0] = lines[0]  # Ridge lines (red)\n",
    "        line_vis[...,1] = lines[1]  # Valley lines (green)\n",
    "        line_vis[...,2] = lines[3]  # Building outline (blue)\n",
    "        axes[i,2].imshow(line_vis)\n",
    "        axes[i,2].set_title('Line Detection')\n",
    "        \n",
    "        # Depth map\n",
    "        depth = targets['depth'][i].numpy()\n",
    "        axes[i,3].imshow(depth, cmap='viridis')\n",
    "        axes[i,3].set_title('Depth Map')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def show_predictions(images, targets, predictions, dataset_type):\n",
    "    \"\"\"Display predictions alongside ground truth.\"\"\"\n",
    "    batch_size = images.shape[0]\n",
    "    fig, axes = plt.subplots(batch_size, 4, figsize=(20, 5*batch_size))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Original image\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        axes[i,0].imshow(img)\n",
    "        axes[i,0].set_title('Original Image')\n",
    "        \n",
    "        # Segmentation prediction\n",
    "        pred_mask = torch.argmax(predictions['segments'][i], dim=0).numpy()\n",
    "        true_mask = targets['segments'][i].numpy()\n",
    "        axes[i,1].imshow(pred_mask, cmap='tab20', alpha=0.7)\n",
    "        axes[i,1].imshow(true_mask, cmap='tab20', alpha=0.3)\n",
    "        axes[i,1].set_title('Segmentation (Pred/True)')\n",
    "        \n",
    "        # Line detection\n",
    "        pred_lines = predictions['lines'][i].numpy()\n",
    "        true_lines = targets['lines'][i].numpy()\n",
    "        line_vis = np.zeros((*pred_lines.shape[1:], 3))\n",
    "        line_vis[...,0] = pred_lines[0]  # Predicted (red)\n",
    "        line_vis[...,1] = true_lines[0]  # True (green)\n",
    "        axes[i,2].imshow(line_vis)\n",
    "        axes[i,2].set_title('Lines (Pred/True)')\n",
    "        \n",
    "        # Depth prediction\n",
    "        pred_depth = predictions['depth'][i].squeeze().numpy()\n",
    "        true_depth = targets['depth'][i].numpy()\n",
    "        depth_diff = np.abs(pred_depth - true_depth)\n",
    "        axes[i,3].imshow(depth_diff, cmap='viridis')\n",
    "        axes[i,3].set_title('Depth Error')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RID Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create RID dataset and dataloader\n",
    "print(\"Creating RID dataloaders...\")\n",
    "rid_train_loader, rid_val_loader = create_dataloaders(\n",
    "    data_paths['rid'],\n",
    "    'rid',\n",
    "    batch_size=config['batch_size'],\n",
    "    num_workers=config['num_workers'],\n",
    "    max_samples=config['max_samples']\n",
    ")\n",
    "\n",
    "print(\"\\nGetting a batch of data...\")\n",
    "images, targets = next(iter(rid_train_loader))\n",
    "\n",
    "print(\"\\nBatch information:\")\n",
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Number of images: {len(images)}\")\n",
    "print(f\"Target keys: {list(targets.keys())}\")\n",
    "\n",
    "# Display the batch\n",
    "print(\"\\nDisplaying batch...\")\n",
    "show_batch(images, targets, 'rid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model with RID Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create model\n",
    "model, criterion = create_model(num_classes=config['num_classes'])\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "# Move batch to device\n",
    "images = images.to(device)\n",
    "device_targets = {k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
    "                 for k, v in targets.items()}\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(images)\n",
    "\n",
    "# Calculate loss\n",
    "loss, losses_dict = criterion(predictions, device_targets)\n",
    "print(f'Total loss: {loss.item():.4f}')\n",
    "for k, v in losses_dict.items():\n",
    "    print(f'{k} loss: {v.item():.4f}')\n",
    "\n",
    "# Move everything back to CPU for visualization\n",
    "images = images.cpu()\n",
    "predictions = {k: v.cpu() for k, v in predictions.items()}\n",
    "targets = {k: v.cpu() if isinstance(v, torch.Tensor) else v\n",
    "          for k, v in targets.items()}\n",
    "\n",
    "# Show predictions\n",
    "show_predictions(images, targets, predictions, 'rid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After verifying RID dataset works:\n",
    "1. Implement RooflineDataset class\n",
    "2. Test Roofline dataset loading and inference\n",
    "3. Implement AIRSDataset class\n",
    "4. Test AIRS dataset loading and inference\n",
    "5. Prepare for AWS SageMaker training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
