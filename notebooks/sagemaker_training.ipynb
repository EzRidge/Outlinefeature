{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Unified Roof Analysis Model on SageMaker\n",
    "\n",
    "This notebook demonstrates training our unified roof analysis model using two datasets:\n",
    "\n",
    "1. RID (Roof Information Dataset)\n",
    "   - Provides detailed roof segmentation\n",
    "   - Has ridge, valley, and eave lines\n",
    "   - Includes depth information\n",
    "\n",
    "2. Roofline-Extraction Dataset\n",
    "   - Focuses on 3D building reconstruction\n",
    "   - Has ridge, hip, and valley lines\n",
    "   - Includes depth maps\n",
    "\n",
    "## Steps:\n",
    "1. Set up SageMaker environment\n",
    "2. Prepare and verify datasets\n",
    "3. Run quick test training\n",
    "4. Start full training\n",
    "5. Monitor progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "# S3 bucket for training data and model artifacts\n",
    "bucket = 'sagemaker-us-east-2-575108929659'\n",
    "prefix = 'unified-roof-model'\n",
    "\n",
    "print(f\"Using bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare and Verify Datasets\n",
    "\n",
    "Our datasets are already in S3 at these locations:\n",
    "- RID: s3://sagemaker-us-east-2-575108929659/roof-data/RID/\n",
    "- Roofline: s3://sagemaker-us-east-2-575108929659/roof-data/Roofline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define dataset paths\n",
    "dataset_paths = {\n",
    "    'rid': f's3://{bucket}/roof-data/RID',\n",
    "    'roofline': f's3://{bucket}/roof-data/Roofline'\n",
    "}\n",
    "\n",
    "# Verify datasets exist\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "def check_s3_path(s3_path):\n",
    "    path_parts = s3_path.replace('s3://', '').split('/')\n",
    "    bucket = path_parts[0]\n",
    "    prefix = '/'.join(path_parts[1:])\n",
    "    \n",
    "    response = s3.list_objects_v2(\n",
    "        Bucket=bucket,\n",
    "        Prefix=prefix,\n",
    "        MaxKeys=1\n",
    "    )\n",
    "    return 'Contents' in response\n",
    "\n",
    "for dataset, path in dataset_paths.items():\n",
    "    exists = check_s3_path(path)\n",
    "    print(f\"{dataset}: {'✓' if exists else '✗'} ({path})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quick Test Training\n",
    "\n",
    "First, we'll run a quick test with just a few batches to verify everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configure test hyperparameters\n",
    "test_hyperparameters = {\n",
    "    'epochs-per-dataset': 2,  # Just 2 epochs for testing\n",
    "    'batch-size': 4,  # Reduced batch size\n",
    "    'gradient-accumulation-steps': 4,  # Accumulate gradients\n",
    "    'learning-rate': 0.001,\n",
    "    'num-workers': 4,\n",
    "    'num-classes': 12,\n",
    "    'datasets': 'rid,roofline',\n",
    "    'test-run': True  # Enable test mode\n",
    "}\n",
    "\n",
    "# Create PyTorch estimator for test\n",
    "test_estimator = PyTorch(\n",
    "    entry_point='sagemaker_train.py',\n",
    "    source_dir='/home/sagemaker-user/Outlinefeature/roof-training/src',\n",
    "    role=role,\n",
    "    framework_version='2.0.1',\n",
    "    py_version='py310',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge',  # NVIDIA A10G GPU instance\n",
    "    hyperparameters=test_hyperparameters,\n",
    "    output_path=f's3://{bucket}/{prefix}/test_output',\n",
    "    code_location=f's3://{bucket}/{prefix}/test_code',\n",
    "    metric_definitions=[\n",
    "        {'Name': 'train:loss', 'Regex': 'Training Loss: ([0-9\\.]+)'},\n",
    "        {'Name': 'val:loss', 'Regex': 'Validation Loss: ([0-9\\.]+)'},\n",
    "        {'Name': 'segments:loss', 'Regex': 'segments: ([0-9\\.]+)'},\n",
    "        {'Name': 'lines:loss', 'Regex': 'lines: ([0-9\\.]+)'},\n",
    "        {'Name': 'depth:loss', 'Regex': 'depth: ([0-9\\.]+)'}\n",
    "    ],\n",
    "    enable_sagemaker_metrics=True\n",
    ")\n",
    "\n",
    "# Start test training\n",
    "test_estimator.fit({\n",
    "    'rid': dataset_paths['rid'],\n",
    "    'roofline': dataset_paths['roofline']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Full Training\n",
    "\n",
    "If the test run succeeds, we'll start the full training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configure full training hyperparameters\n",
    "hyperparameters = {\n",
    "    'epochs-per-dataset': 20,  # Full training\n",
    "    'batch-size': 4,  # Reduced batch size\n",
    "    'gradient-accumulation-steps': 4,  # Accumulate gradients\n",
    "    'learning-rate': 0.001,\n",
    "    'num-workers': 4,\n",
    "    'num-classes': 12,\n",
    "    'datasets': 'rid,roofline',\n",
    "    'test-run': False  # Disable test mode\n",
    "}\n",
    "\n",
    "# Create PyTorch estimator for full training\n",
    "estimator = PyTorch(\n",
    "    entry_point='sagemaker_train.py',\n",
    "    source_dir='/home/sagemaker-user/Outlinefeature/roof-training/src',\n",
    "    role=role,\n",
    "    framework_version='2.0.1',\n",
    "    py_version='py310',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge',  # NVIDIA A10G GPU instance\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=f's3://{bucket}/{prefix}/output',\n",
    "    code_location=f's3://{bucket}/{prefix}/code',\n",
    "    metric_definitions=[\n",
    "        {'Name': 'train:loss', 'Regex': 'Training Loss: ([0-9\\.]+)'},\n",
    "        {'Name': 'val:loss', 'Regex': 'Validation Loss: ([0-9\\.]+)'},\n",
    "        {'Name': 'segments:loss', 'Regex': 'segments: ([0-9\\.]+)'},\n",
    "        {'Name': 'lines:loss', 'Regex': 'lines: ([0-9\\.]+)'},\n",
    "        {'Name': 'depth:loss', 'Regex': 'depth: ([0-9\\.]+)'}\n",
    "    ],\n",
    "    enable_sagemaker_metrics=True\n",
    ")\n",
    "\n",
    "# Start full training\n",
    "estimator.fit({\n",
    "    'rid': dataset_paths['rid'],\n",
    "    'roofline': dataset_paths['roofline']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Monitor Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get training job name and CloudWatch URL\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "region = sagemaker_session.boto_region_name\n",
    "print(f'Training job name: {training_job_name}')\n",
    "\n",
    "# Get CloudWatch metrics URL\n",
    "cloudwatch_url = f'https://{region}.console.aws.amazon.com/cloudwatch/home?region={region}#metricsV2:graph=~(metrics~(~(~\\'AWS*2fSageMaker~\\'TrainingJobMetrics~\\'TrainingJobName~\\'{training_job_name}~\\'metric~\\'train*3aloss))~view~\\'timeSeries~stacked~false~region~\\'{region}~stat~\\'Average~period~60)'\n",
    "print(f'\\nView metrics at: {cloudwatch_url}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}